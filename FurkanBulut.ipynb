{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "17728ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------\n",
      "--------------------------------------------\n"
     ]
    },
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 1 fields in line 28, saw 367\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 47>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     44\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://github.com/FurkanBulut00/FurkanBulutDeploy/blob/main/IRIS.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# --- Importing Dataset ---\u001b[39;00m\n\u001b[1;32m---> 47\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# --- Reading Dataset ---\u001b[39;00m\n\u001b[0;32m     50\u001b[0m dataset\u001b[38;5;241m.\u001b[39mhead()\u001b[38;5;241m.\u001b[39mstyle\u001b[38;5;241m.\u001b[39mbackground_gradient(cmap \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPurples\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mset_properties(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfont-family\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSegoe UI\u001b[39m\u001b[38;5;124m'\u001b[39m})\u001b[38;5;241m.\u001b[39mhide_index()\n",
      "File \u001b[1;32mD:\\anaconda\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\anaconda\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    666\u001b[0m     dialect,\n\u001b[0;32m    667\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    677\u001b[0m )\n\u001b[0;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\anaconda\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:581\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[0;32m    580\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[1;32m--> 581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\anaconda\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1254\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1252\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[0;32m   1253\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1254\u001b[0m     index, columns, col_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1255\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1256\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mD:\\anaconda\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:225\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[1;32m--> 225\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    226\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[0;32m    227\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[1;32mD:\\anaconda\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:805\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mD:\\anaconda\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:861\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mD:\\anaconda\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:847\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mD:\\anaconda\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:1960\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 1 fields in line 28, saw 367\n"
     ]
    }
   ],
   "source": [
    "# --- Importing Libraries ---\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import yellowbrick\n",
    "\n",
    "from statsmodels.graphics.gofplots import qqplot\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from yellowbrick.classifier import PrecisionRecallCurve, ROCAUC, ConfusionMatrix\n",
    "from yellowbrick.style import set_palette\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "from yellowbrick.model_selection import LearningCurve, FeatureImportances\n",
    "from yellowbrick.contrib.wrapper import wrap\n",
    "\n",
    "# --- Libraries Settings ---\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_style('whitegrid')\n",
    "set_palette('dark')\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "olcum = ( \"manhattan\" , \"euclidean\" )\n",
    "\n",
    "print(\"--------------------------------------------\")\n",
    "\n",
    "# --- Create List of Color Palletes ---\n",
    "purple_grad = ['#491D8B', '#6929C4', '#8A3FFC', '#A56EFF', '#BE95FF']\n",
    "color_mix = ['#29066B', '#7D3AC1', '#AF4BCE', '#DB4CB2', '#EB548C']\n",
    "black_grad = ['#100C07', '#3E3B39', '#6D6A6A', '#9B9A9C', '#CAC9CD']\n",
    "\n",
    "print(\"--------------------------------------------\")\n",
    "def read_file(url):\n",
    "    url = url + \"?raw=true\"\n",
    "    df = pd.read_csv(url)\n",
    "    return df\n",
    "url = \"https://github.com/FurkanBulut00/FurkanBulutDeploy/blob/main/IRIS.csv\"\n",
    "\n",
    "# --- Importing Dataset ---\n",
    "dataset = pd.read_csv(url)\n",
    "\n",
    "# --- Reading Dataset ---\n",
    "dataset.head().style.background_gradient(cmap = 'Purples').set_properties(**{'font-family': 'Segoe UI'}).hide_index()\n",
    "\n",
    "# --- Print Dataset Info ---\n",
    "print('\\033[35m\\033[1m'+'.: Dataset Info :.')\n",
    "print('\\033[0m\\033[35m*' * 20)\n",
    "print('\\033[0m'+'Total Rows:'+'\\033[35m\\033[1m', dataset.shape[0])\n",
    "print('\\033[0m'+'Total Columns:'+'\\033[35m\\033[1m', dataset.shape[1])\n",
    "print('\\033[0m\\033[35m*' * 20)\n",
    "print('\\n')\n",
    "\n",
    "# --- Print Dataset Detail ---\n",
    "print('\\033[1m'+'.: Dataset Details :.')\n",
    "print('\\033[0m\\033[35m*' * 22 +'\\033[0m')\n",
    "dataset.info(memory_usage = False)\n",
    "\n",
    "\n",
    "# --- Seperating Dependent Features ---\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, -1].values\n",
    "# --- Perform Label Encoding ---\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "# --- Label Encoding Mappings ---\n",
    "idx = [0, 1, 2]\n",
    "print('\\033[35m\\033[1m'+'.: Target Variable After Encoding :.')\n",
    "print('\\033[0m\\033[35m*' * 37)\n",
    "pd.DataFrame({'Label': idx, 'Target': le.classes_}, columns = ['Label', 'Target']).style.background_gradient(cmap = 'Purples').set_properties(**{'font-family': 'Segoe UI'}).hide_index()\n",
    "\n",
    "# --- Splitting Dataset into 80:20 w/ Stratified Random Sampling ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, stratify = y, random_state = 0)\n",
    "\n",
    "\n",
    "# --- Print Train Test Info ---\n",
    "print('\\033[35m\\033[1m'+'.:. Train Test Info .:.')\n",
    "print('\\033[0m\\033[35m*' * 25)\n",
    "print('\\033[35m\\033[1m'+'>> Train Set')\n",
    "print('\\t\\033[0m'+'.: Total data in train set:'+'\\033[35m\\033[1m', X_train.shape[0])\n",
    "print('\\t\\033[0m'+'.: Total target data in train set:'+'\\033[35m\\033[1m', y_train.shape[0])\n",
    "print('\\t\\033[0m'+'.: Total column in train set:'+'\\033[35m\\033[1m', X_train.shape[1])\n",
    "print('\\n\\033[35m\\033[1m'+'>> Test Set')\n",
    "print('\\t\\033[0m'+'.: Total data in test set:'+'\\033[35m\\033[1m', X_test.shape[0])\n",
    "print('\\t\\033[0m'+'.: Total target data in test set:'+'\\033[35m\\033[1m', y_test.shape[0])\n",
    "print('\\t\\033[0m'+'.: Total column in test set:'+'\\033[35m\\033[1m', X_test.shape[1])\n",
    "\n",
    "# --- Applying SVM ---\n",
    "SVMclassifier = SVC()\n",
    "SVMclassifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred_SVM = SVMclassifier.predict(X_test)\n",
    "\n",
    "# --- SVM Accuracy ---\n",
    "SVMAcc = accuracy_score(y_pred_SVM, y_test)\n",
    "print('.:. Support Vector Machine Accuracy:'+'\\033[35m\\033[1m {:.2f}%'.format(SVMAcc*100)+' \\033[0m.:.')\n",
    "\n",
    "# --- SVM Classification Report ---\n",
    "print('\\033[35m\\033[1m\\n.: Classification Report'+'\\033[0m')\n",
    "print('*' * 25)\n",
    "print(classification_report(y_test, y_pred_SVM))\n",
    "\n",
    "# --- Performance Evaluation ---\n",
    "print('\\033[35m\\033[1m'+'.: Performance Evaluation'+'\\033[0m')\n",
    "print('*' * 26)\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize = (14, 10))\n",
    "\n",
    "# --- SVM Confusion Matrix ---\n",
    "svmmatrix = ConfusionMatrix(SVMclassifier, ax = ax1, cmap = 'RdPu', title = 'Support Vector Machine Confusion Matrix')\n",
    "svmmatrix.fit(X_train, y_train)\n",
    "svmmatrix.score(X_test, y_test)\n",
    "svmmatrix.finalize()\n",
    "\n",
    "# --- SVM ROC AUC ---\n",
    "svmrocauc = ROCAUC(SVMclassifier, ax = ax2, title = 'Support Vector Machine ROC AUC Plot')\n",
    "svmrocauc.fit(X_train, y_train)\n",
    "svmrocauc.score(X_test, y_test)\n",
    "svmrocauc.finalize()\n",
    "\n",
    "# --- SVM Learning Curve ---\n",
    "svmlc = LearningCurve(SVMclassifier, ax = ax3, title = 'Support Vector Machine Learning Curve')\n",
    "svmlc.fit(X_train, y_train)\n",
    "svmlc.finalize()\n",
    "\n",
    "# --- SVM Precision Recall Curve ---\n",
    "svmcurve = PrecisionRecallCurve(SVMclassifier, ax = ax4, ap_score = True, iso_f1_curves = True,\n",
    "                                title = 'Support Vector Machine Precision-Recall Curve')\n",
    "svmcurve.fit(X_train, y_train)\n",
    "svmcurve.score(X_test, y_test)\n",
    "svmcurve.finalize()\n",
    "\n",
    "plt.tight_layout();\n",
    "\n",
    "!pip freeze > requirements.txt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e03c5dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
